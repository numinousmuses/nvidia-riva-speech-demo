{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Welcome!\n",
    "\n",
    "[NVIDIA Riva](https://developer.nvidia.com/riva) is a GPU-accelerated SDK for building Speech AI applications that are customized for your use case and deliver real-time performance.\n",
    "\n",
    "The [Riva Speech Skills Quick Start Guide](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/quick-start-guide.html#quick-start-guide) is a starting point to try out Riva; specifically, the guide explains how to quickly deploy pretrained models on a local workstation and run a sample client. \n",
    "\n",
    "In this lab, a similar process was followed to deploy pretrained conversational AI models to a cloud instance of the Riva server.   The JupyterLab notebooks in this tutorial are part of the [Riva Speech Clients container](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/riva/containers/riva-speech-client)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Before You Begin...\n",
    "It takes a few minutes for all the models to be copied to the server.  Execute the following cell and wait for the \"Server ready!\" response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import grpc\n",
    "import riva_api.health_pb2 as rhlth\n",
    "import riva_api.health_pb2_grpc as rhlth_srv\n",
    "\n",
    "# Set up a health request for Riva\n",
    "channel = grpc.insecure_channel(\"riva-speech:50051\")\n",
    "riva_health = rhlth_srv.HealthStub(channel)\n",
    "req = rhlth.HealthCheckRequest()\n",
    "\n",
    "# Check for a valid response from the server\n",
    "not_ready = True\n",
    "response = None\n",
    "while not_ready:\n",
    "    try:\n",
    "        response = riva_health.Check(req)\n",
    "    except:\n",
    "        print(\"Server not ready! Trying again in 20 seconds\")\n",
    "        sleep(20)\n",
    "    if response is not None:\n",
    "        print(\"Server ready!\")\n",
    "        not_ready = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Once the server is up, move on to the Riva demo notebooks:\n",
    "\n",
    "#### [1. Riva_speech_API_demo](Riva_speech_API_demo.ipynb).\n",
    "#### [2. Riva_speech_QA_demo](Riva_speech_QA_demo.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
